# -*- coding: utf-8 -*-
"""00-main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10ZbGX1ciXKnONsyCCPGboraC01y_BW-u
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn
from sklearn.model_selection import *
from sklearn.metrics import *
from sklearn.svm import SVC,SVR
from sklearn.linear_model import SGDRegressor,SGDClassifier,RidgeClassifier
from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,NearestNeighbors
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor
from catboost import CatBoost,CatBoostClassifier,CatBoostRegressor

data = pd.read_csv('./cleaned_data.csv')
data.sample(frac=1)
test_data = pd.read_csv('./cleaned_test.csv')
sample_sub = pd.read_csv('./gender_submission.csv')

"""## pd.get_dummies() vs OneHotEncoding() and MinMaxScalar() vs OneHotEncoding() and StandordScalar()

### pd.get_dummies()
"""

pd_get_dummied_mean = []

# ## 2.45810593901
# for _ in range(25):
#   pd_get_dummied_data = pd.get_dummies(data)
#   X = pd_get_dummied_data.drop('Survived',axis=1)
#   y = pd_get_dummied_data['Survived']
#   X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
#   model = CatBoostClassifier(task_type='GPU')
#   model.fit(X_train,y_train,verbose=1)
#   preds = np.round(model.predict(X_test))
#   print(accuracy_score(y_test,preds))
#   pd_get_dummied_mean.append(accuracy_score(y_test,preds))
# print(np.mean(pd_get_dummied_mean))

"""### OneHotEncoding() + MinMaxScalar()"""

data.dtypes

# ## 2.44382022472
# for _ in range(25):
#   X = data.drop('Survived',axis=1)
#   y = data['Survived']
#   X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
#   one_hot_encoding_and_min_max_scalar_mean = []
#   from sklearn.preprocessing import OneHotEncoder,StandardScaler,MinMaxScaler
#   from sklearn.compose import make_column_transformer
#   ct = make_column_transformer(
#       (OneHotEncoder(),['Name','Sex','Ticket','Cabin','Embarked']),
#       (MinMaxScaler(),['PassengerId','Pclass','SibSp','Parch','Fare']),
#   )
#   ct.fit(X)
#   X_train = ct.transform(X_train)
#   X_test = ct.transform(X_test)
#   X_train = X_train.toarray()
#   X_test = X_test.toarray()
#   model = CatBoostClassifier(task_type='GPU')
#   model.fit(X_train,y_train,verbose=1)
#   preds = np.round(model.predict(X_test))
#   print(accuracy_score(y_test,preds))
#   one_hot_encoding_and_min_max_scalar_mean.append(accuracy_score(y_test,preds))
# print(np.mean(one_hot_encoding_and_min_max_scalar_mean))

"""### OneHotEncoding() + StandordScalar()"""

# ## 1.60112359551
# for _ in range(10):
#   X = data.drop('Survived',axis=1)
#   y = data['Survived']
#   X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
#   one_hot_encoding_and_standord_scalar_mean = []
#   from sklearn.preprocessing import OneHotEncoder,StandardScaler,MinMaxScaler
#   from sklearn.compose import make_column_transformer
#   ct = make_column_transformer(
#       (OneHotEncoder(),['Name','Sex','Ticket','Cabin','Embarked']),
#       (StandardScaler(),['PassengerId','Pclass','SibSp','Parch','Fare']),
#   )
#   ct.fit(X)
#   X_train = ct.transform(X_train)
#   X_test = ct.transform(X_test)
#   X_train = X_train.toarray()
#   X_test = X_test.toarray()
#   model = CatBoostClassifier(task_type='GPU')
#   model.fit(X_train,y_train,verbose=1)
#   preds = np.round(model.predict(X_test))
#   print(accuracy_score(y_test,preds))
#   one_hot_encoding_and_standord_scalar_mean.append(accuracy_score(y_test,preds))
# print(np.mean(one_hot_encoding_and_standord_scalar_mean))

## 2.44382022472
X = data.drop('Survived',axis=1)
y = data['Survived']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
one_hot_encoding_and_min_max_scalar_mean = []
from sklearn.preprocessing import OneHotEncoder,StandardScaler,MinMaxScaler,RobustScaler
from sklearn.compose import make_column_transformer
ct = make_column_transformer(
    (OneHotEncoder(handle_unknown='ignore'),['Name','Sex','Ticket','Cabin','Embarked']),
    (RobustScaler(),['PassengerId','Pclass','SibSp','Parch','Fare']),
)
ct.fit(X)
X_train = ct.transform(X_train)
X_test = ct.transform(X_test)
X_train = X_train.toarray()
X_test = X_test.toarray()

"""## Modelling"""

from sklearn.svm import SVC,SVR
from sklearn.linear_model import SGDRegressor,SGDClassifier,RidgeClassifier,LogisticRegression
from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,NearestNeighbors
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor
from catboost import CatBoost,CatBoostClassifier,CatBoostRegressor
models = [
    ['SVC',SVC()],
    ['SGDClassifier',SGDClassifier()],
    ['RidgeClassifier',RidgeClassifier()],
    ['KNeighborsClassifier',KNeighborsClassifier()],
    ['GaussianNB',GaussianNB()],
    ['RandomForestClassifier',RandomForestClassifier()],
    ['CatBoost',CatBoost()],
    ['CatBoostClassifier',CatBoostClassifier()],
    ['RandomForestClassifier2',RandomForestClassifier(n_estimators=100, oob_score = True, random_state = 1)],
    ['LogisticRegression',LogisticRegression(solver='liblinear')],
]
maxes = []
for _ in range(10):
  results = {}
  for model in models:
      print(model)
      model_name = model[0]
      model = model[1]
      model.fit(X_train,y_train)
      try:
          accuracy = model.score(X_test,y_test)
          results[model_name] = accuracy
      except:
          preds = model.predict(X_test)
          preds = np.round(preds)
          accuracy = accuracy_score(y_test,preds)
          results[model_name] = accuracy
      print(f'{model_name} : {accuracy}')
  print(results)
  maxes.append(max(results, key=results.get))

maxes

from collections import Counter
occurence_count = Counter(maxes)
print(occurence_count.most_common(1)[0][0])

# grid = {
#     "n_estimators":[100,250,500,1000],
#     "max_depth":[None,5,10,round(12.5)],
#     "max_features":["auto","sqrt",'log2'],
#     "min_samples_split":[2,5],
#     "min_samples_leaf":[2,5],
#     'bootstrap':[False,True],
#     'warm_start':[False,True]
# }
# model = RandomForestClassifier()
# gs_model = GridSearchCV(model,param_grid=grid,cv=round(2.5),verbose=2)
# gs_model.fit(X_train,y_train)
# print(f'{gs_model.score(X_test,y_test)}')

# grid = {
#     'alpha':[1,round(2.5),5,round(7.5),10,round(12.5),25,50,75,100],
#     'fit_intercept':[True,False],
#     'normalize':[False,True],
#     'copy_X':[False,True],
#     'max_iter':[None,1,round(2.5)],
#     'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']
# }
# model = RidgeClassifier()
# gs_model = GridSearchCV(model,param_grid=grid,cv=round(2.5),verbose=2)
# gs_model.fit(X_train,y_train)
# print(f'{gs_model.score(X_test,y_test)}')

# grid = {
#     'n_neighbors':[round(2.5),5,round(7.5),10,round(12.5),25,50,75,100],
#     'weights':['distance','uniform'],
#     'algorithm':['auto', 'ball_tree','kd_tree','brute'],
#     'leaf_size':[round(12.5),25,50,75,100],
# }
# model = KNeighborsClassifier()
# gs_model = GridSearchCV(model,param_grid=grid,cv=round(2.5),verbose=2)
# gs_model.fit(X_train,y_train)
# print(f'{gs_model.score(X_test,y_test)}')

gs_model.best_estimator_

test_data

preds = gs_model.predict(ct.transform(test_data).toarray())

submission = pd.DataFrame({'PassengerId':test_data['PassengerId'],'Survived':preds})

submission

submission.to_csv('./submission-5.csv',index=False)

